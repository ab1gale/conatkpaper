
\section{\xxx Overview}\label{sec:overview}

% As concurrency attacks raised many security challenges and the concurrency 
% errors that can lead to these attacks are hidden in the excessive number of 
% reports, we build \xxx, an automated concurrency attack detection 
% framework. 

This section first presents a major challenge on realizing the 
directed concurrency attack detection approach (\S\ref{sec:challenge}), gives an 
overview of \xxx's architecture with main components and workflow
(\S\ref{sec:arch}), and then  gives an example to show how it works 
(\S\ref{sec:example}).

\subsection{Challenge: Accuracy v.s. Scalability}\label{sec:challenge}

A crucial component for \xxx is a good bug-to-attack analysis, but it is 
technically challenging to make this analysis both accurate (report few false 
reports and miss few real bugs) and scalable (work with large programs). As 
mentioned in \S\ref{sec:intro}, static analyses are often easy to be scalable as 
they can see what a compiler can see, but because of the lack of runtime effects 
(\eg, functions being executed and branches taken), they suffer excessive 
false reports (\eg, 84\% reports in RELAY~\cite{relay:fse07} were false 
reports).

% An alternative technique is symbolic execution~\cite{klee:osdi08}) because it 
% can systematically explore both sides of branch statements to find bugs. 
% Although symbolic execution has shown to effectively detect lots of software 
% bugs in utility programs, it is still impractical to scale to large programs 
% (\eg, servers and Linux kernels) even with the help of targeted consequence 
% analysis~\cite{woodpecker:asplos13}.

To better identify runtime effects, symbolic execution~\cite{klee:osdi08} 
systematically explores branches and leverages the program paths to identify 
buggy inputs. However, this technique is notoriously difficult to scale to large 
programs (\eg, \apache and Linux kernel) because these programs typically have 
too many functions and program paths~\cite{woodpecker:asplos13}.
% For instance, 
% adding an \v{if} statement in 
% % code will double the number of program paths.

Alternatively, dynamic analyses can accurately capture runtime effects 
(\eg,~\cite{pres:sosp09,odr:sosp09}), but they can analyze only the executed 
program path with the exact input and schedule. If a concurrency 
bug's attack requires another input to trigger in another program 
path, dynamic analyses may miss the attack.

% Insight for the first challenge.
Fortunately, this challenge can be mitigated via the two optimistic patterns 
(\S\ref{sec:patterns}) in our study: concurrency attack sites are 
explicit, and bugs and their attacks often share similar call stack prefixes.
These patterns imply that a concurrency bug only affects a small portion 
of functions and program paths (and thus a small portion of inputs). Thus, 
we can combine the attack sites (static effects) and calls stacks in reports 
(dynamic effects), then our static analysis can skip analyzing many functions 
and program paths that do not comply with these effects, making \xxx reasonably 
accurate and scalable.

% 
% Intuitively, after a concurrency bug is triggered, 
% % other than global memory access, the memory corrupted by this bug should 
% mainly 
% propagate within current function, or from current function to 
% callees/callers through arguments, or propagate to callers through return 
% values of current function. 


\subsection{\xxx Architecture}\label{sec:arch}

Figure~\ref{fig:arch} presents \xxx's architecture with five key components:
the concurrency error detector, the static adhoc synchronization detector,
dynamic race verifier, static vulnerability detector and dynamic vulnerability
verifier.

\xxx's work as follows. (1) A concurrency bug detector first detects bugs for the 
given program inputs. (2) Then, based on the detected results, 
\xxx's adhoc synchronization detector analyzes the reports and LLVM 
bitcode to find adhoc synchronizations. After obtaining the adhoc 
synchronization locations, \xxx automatically annotates program source code 
with \tsan markups and re-runs the detector. (3) Then, \xxx passes the 
re-generated bug reports to its race verifier to check whether bugs will 
actually occur. (4) \xxx's static vulnerability analyzer conducts a 
forward data \& control flow analysis to identify potential bug-to-attack 
propagations as vulnerable input hints. (5) Eventually, \xxx's vulnerability 
verifier re-runs the program and checks whether an attack can actually be 
realized.
% All of our components are fully automatic except the 
% last component which
% requires developers intervention.

% Figure~\ref{fig:arch} presents \xxx's architecture with four key components: 
% the concurrency error detector (for short, \emph{detector}), the static false positive 
% filter (\emph{static-filter}), the dynamic false positive filter (\emph{dynamic-filter})
% and the security consequence analysis tool 
% (\emph{analyzer}). \xxx takes both program source code and inputs, and it 
% outputs real or potential reports of concurrency attacks. This project 
% targets open source C/C++ programs. Program inputs can be popular workloads or 
% developer test suites of these programs.
% 
% The detector takes a program's inputs and executable and outputs concurrency 
% error reports. This paper leverages \tsan~\cite{tsan:wbia09} for 
% application programs and \ski~\cite{ski:osdi14} for kernels. We chose these two 
% detectors because they are both open source, popular, and have shown to detect 
% harmful bugs in many large programs. We modified these two detectors to match the 
% input formats for our filter and analyzer (\S\ref{sec:tool}).
% 
% As presented in our study, one common issue in existing concurrency bug 
% detectors is that their reports are typically enormous and deeply 
% bury the vulnerable ones. As later shown in section~\ref{sec:evaluation}, more than
% 99\% of these reports are false positives, thus passing all these
% reports to \xxx's analyzer is time consuming and helpless on detecting
% concurrency attacks.
% 
% To address this issue, we adopt a hybrid way to efficiently remove false positives
% from the generated race reports. Our filter components take detector's original race
% reports, program executable, program input, and LLVM bitcode to filter out harmless
% reports. First, our static filter currently handles
% three types of benign reports, including duplicate call stack reports,
% ad-hoc and self-implemented synchronization primitives. Then, our dynamic filter does
% a further verification based on the results generated by our static filter. In
% short, our dynamic filter tries to automatically reproduce the race by running
% the program under \lldb debugger.
% In our evaluation, our hybrid filters are sufficient to 
% prune almost all false positives from the detector without missing harmful ones.
% % , and more types can be added.
% 
% Our analyzer component takes the remaining, potentially vulnerable reports from 
% the filter, and does static analysis on the LLVM bitcode to identify potential 
% security consequence of each report. The analyzer starts from the first LLVM 
% \v{load} (memory read) instruction on a bug report's corrupted memory and does 
% inter-procedural analysis on how this corrupted read value propagates through 
% data flows and control flows. To achieve scalability to large programs, the 
% analyzer does the propagation analysis \wrt current call stack of the 
% read instruction. More details on the analyzer will be given in 
% \S\ref{sec:algo}.

\subsection{Example}\label{sec:example}
% 
% We'll use an example to demonstrate how \xxx's components work together to
% detect a real world concurrency attack.
% \libsafe is 

Figure~\ref{fig:libsafe} shows a concurrency attack in \libsafe, a user-level 
security library which dynamically intercepts all the Libc memory functions to detect buffer 
overflows. When \libsafe detects a buffer overflow, it sets a global variable 
\v{dying} to 1 to indicate that current process will be killed shortly, and 
then it kills the program. If this variable is set, \libsafe will stop performing
security checks on memory functions. Unfortunately, there is a data 
race on \v{dying} because access to this variable is not protected by mutex. 
Therefore, between the moment \v{dying} is set and the moment the entire process 
is killed, a thread calling memory functions in this process may leverage the 
race on \v{dying} to bypass buffer overflow checks.

We have constructed a C program with \libsafe to trigger this race, bypassed a 
stack overflow check for a vulnerability site, \v{strcpy()}, and gotten a shell by 
injecting our own malicious code. Note that in this attack, the race and the 
vulnerability site are in different functions, and the race affects the
vulnerability site through an \v{if} control-dependency at line 164. Existing 
consequence 
analysis tools~\cite{conseq:asplos11,yamaguchi:sp14,livshits05finding} are 
inadequate to detect this attack because they lack either inter-procedural or 
control-flow analysis.

\xxx started from the detection of the data races between line 145 and line 1640.
Our dynamic race verifier verifies this race and pass this report to our
vulnerability analyzer. Our vulnerability analyzer starts from the ``read''
side call stack of the race shown in Figure~\ref{fig:call_stack} 
and conducts a inter-procedural static analysis to detect which vulnerability 
site may be affected by this race by tracking data and control flows.

As shown in Figure~\ref{fig:libsafe_result}, \xxx reported one memory operation 
at line 165 as a vulnerable operation. Our vulnerability report includes the 
reasoning (a dangerous function will be control-dependent on the corrupted 
branch statement at line 164) and what are the branches to reach the 
vulnerability operation. Our report indicates that a \v{strcpy()} function will 
be called with the original parameters without the actual security checks in 
\v{stack\_check()}. At the end, our vulnerability verifier verifies this 
vulnerability by re-running the program and satisfies the branches to 
eventually trigger the vulnerability. In order to satisfy the branches, our 
vulnerability verifier requires user intervention to decide the execution order 
of the racing instructions and input tunning.

\begin{figure}
  \centering
  \lstset{basicstyle=\ttfamily\fontsize{6}{6}\selectfont,
  morekeywords={_bytes,_sumbytes}}
  \mbox{\lstinputlisting[mathescape,boxpos=t]{code/libsafe_callstack.txt}}
  \vspace{-.1in}
  \caption{{\em \libsafe call stack}. \rm {Line numbers refer to 
Figure~\ref{fig:libsafe}.}
   }
  \vspace{-.1in}
  \label{fig:call_stack}
\end{figure}


\begin{figure}
  \centering
  \lstset{basicstyle=\ttfamily\fontsize{6}{6}\selectfont,
  morekeywords={_bytes,_sumbytes}}
  \mbox{\lstinputlisting[mathescape,boxpos=t]{code/libsafe_result.txt}}
  \vspace{-.1in}
  \caption{{\em \xxx vulnerable input hint on the \libsafe attack.} \rm 
{Line 
numbers refer to Figure~\ref{fig:libsafe}.} 
  \vspace{-.2in}
  }
  \label{fig:libsafe_result}
\end{figure}

% 
% TBD: heming, ephasis we are inter-procedural, capture indirect control flow 
% propagation.

%The example needs to show two benefits: with the bug report only, but the 
%vulnerability did not triggered in the detector's run, but with our backend 
%report, we idenfied those critical branches and function calls, refined our 
%workloads, and then triggered this attack. And we can trigger this attack with 
%only few executions.

% Our design adheres to the following goals.
